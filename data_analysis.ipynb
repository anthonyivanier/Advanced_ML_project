{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JI7Z5vHLwt0C"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('landmarks.csv')"
      ],
      "metadata": {
        "id": "TCajqcrXw5RH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# pretreatment\n",
        "\n",
        "We shift point 0 (wrist) to (0,0) and normalize so that the length between point 0 and 9 (the distance between the wrist and the joint connecting the middle finger to the palm) is 1."
      ],
      "metadata": {
        "id": "Yl-5fj8TxOEq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "l = np.sqrt((df.x_9-df.x_0)**2 + (df.y_9-df.y_0)**2)\n",
        "for i in range(20,0,-1):\n",
        "  df['x_'+str(i)] = (df['x_'+str(i)]-df.x_0)/l\n",
        "  df['y_'+str(i)] = (df['y_'+str(i)]-df.y_0)/l"
      ],
      "metadata": {
        "id": "JtOUTLkz5zdg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ML treatment"
      ],
      "metadata": {
        "id": "npqCNyXF1361"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We define the predictor variables and the target one\n",
        "\n",
        "predictor=[]\n",
        "for i in range(21):\n",
        "  predictor.append(\"x_\"+str(i))\n",
        "  predictor.append(\"y_\"+str(i))\n",
        "\n",
        "target = ['lettre']"
      ],
      "metadata": {
        "id": "iPul_Yd2NBz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "metadata": {
        "id": "qOvv72a80mm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=df[predictor]\n",
        "y = df[target]"
      ],
      "metadata": {
        "id": "orI-mJa-pouw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBrV72DEp_z4",
        "outputId": "654d9407-4c5b-48d3-afc1-b94bcabe697c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We separate into datasets for the training and for the test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "TL-z3JgBqFwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "cowafC6kme1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Definition of the model and learning"
      ],
      "metadata": {
        "id": "ah5obd5076Iu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Q89vZxMmoLTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)"
      ],
      "metadata": {
        "id": "cgQyVgA3oSLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test of the model"
      ],
      "metadata": {
        "id": "1WBXVTgw8BPF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Loss: {loss}, Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSQJmnTtoYfO",
        "outputId": "6bcc127d-d792-4595-bde8-6f4b0373b967"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0327 - accuracy: 0.9943\n",
            "Loss: 0.032673243433237076, Accuracy: 0.9942638874053955\n"
          ]
        }
      ]
    }
  ]
}